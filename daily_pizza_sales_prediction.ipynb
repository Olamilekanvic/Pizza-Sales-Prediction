{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f7898f",
   "metadata": {},
   "source": [
    "# Daily Pizza Sales Prediction\n",
    "\n",
    "\n",
    "#### Project Workflow\n",
    "1. Understand the Dataset\n",
    "- Review all columns and their meanings (you‚Äôve already done this ‚Äî great start!)\n",
    "- Identify which variables are:\n",
    "- Independent (features): weather, promotions, school status, holidays, etc.\n",
    "- Dependent (target): daily_sales\n",
    "2. Clean and Prepare the Data\n",
    "- Check for missing values or anomalies (e.g., nulls in temperature or sales)\n",
    "- Convert date column to datetime format\n",
    "- Create new features if needed:\n",
    "- Week number\n",
    "- Is exam week\n",
    "- Ramadan or Lent flag (already modeled, but you can double-check)\n",
    "3. Explore the Data (EDA)\n",
    "Use visualizations to uncover patterns:\n",
    "- üìà Line plots of sales over time\n",
    "- üìä Bar charts comparing average sales by:\n",
    "- Day of week\n",
    "- Month\n",
    "- Holiday vs non-holiday\n",
    "- School in session vs strike\n",
    "- üìâ Boxplots to see sales distribution by weather or promotion\n",
    "- üìå Correlation heatmap to see which features influence sales most\n",
    "4. Model Sales Drivers\n",
    "- Use regression models (e.g., Linear Regression, Random Forest, XGBoost) to predict daily_sales\n",
    "- Evaluate feature importance: which variables drive sales the most?\n",
    "- Try time series models (e.g., ARIMA, Prophet) if you're forecasting future sales\n",
    "5. Segment Your Insights\n",
    "- Compare sales during:\n",
    "- Strike vs normal periods\n",
    "- Ramadan vs non-Ramadan\n",
    "- Exam weeks vs regular weeks\n",
    "- Identify high-performing days (e.g., Fridays with promotions)\n",
    "6. Make Recommendations\n",
    "Based on your findings, suggest:\n",
    "- Best times to run promotions\n",
    "- How to prepare for low-traffic periods (e.g., strikes, Lent)\n",
    "- Staffing or inventory adjustments based on seasonality\n",
    "7. Present Your Work\n",
    "- Create a dashboard (Excel, Power BI, or Tableau)\n",
    "- Summarize key insights in a slide deck or report\n",
    "- Include visuals, trends, and actionable takeaways\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318a010",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9895cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dataset\n",
    "df = pd.read_csv('pizza_sales_2021_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b33bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3421e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ramadan', 'lent'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac750a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa88badd",
   "metadata": {},
   "source": [
    "`Note: `In the `public_holiday_name` column, missing values likely mean ‚Äúnot a public holiday‚Äù ‚Äî which is perfectly valid. So these aren‚Äôt errors or gaps in data collection, they‚Äôre just non-holiday days.\n",
    "- Since `is_holiday` as a Boolean column ‚Äî so you can use that to filter or group.\n",
    "- Also, When `is_holiday` = False, it‚Äôs expected that public_holiday_name = NaN.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900268ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Duplicates\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check and FIx Data Types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60fcdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date column to datetime dtype\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ce351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Category columns to category dtype\n",
    "cat_cols = ['day_of_week', 'month', 'public_holiday_name', 'university_calendar_status', 'weather']\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Boolean columns to bool dtype\n",
    "bool_cols = ['is_weekend', 'is_holiday', 'is_school_in_session', 'promotion']\n",
    "for col in bool_cols:\n",
    "    df[col] = df[col].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Numeric Columns to floats type\n",
    "num_cols = ['temperature_C', 'foot_traffic_index', 'student_density_index', 'daily_sales_NGN', 'transactions_count', 'avg_order_value_NGN']\n",
    "for col in num_cols:  \n",
    "    df[col] = df[col].astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889abe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Time Continuity to ensure no missing dates\n",
    "\n",
    "# Create a complete date range\n",
    "full_range = pd.date_range(start=df['date'].min(), end=df['date'].max())\n",
    "\n",
    "# Compare with actual dates\n",
    "missing_dates = full_range.difference(df['date'])\n",
    "\n",
    "print(f\"Missing dates: {missing_dates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be000b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb990159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fe0d7c3",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6dfb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram for each numerical attribute\n",
    "df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fced124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats\n",
    "print(\n",
    "    df[['daily_sales_NGN', 'temperature_C', 'student_density_index', 'foot_traffic_index', 'transactions_count', 'avg_order_value_NGN']].describe()\n",
    ")\n",
    "\n",
    "\n",
    "# Visualizing boxplots for numerical columns\n",
    "for col in ['daily_sales_NGN', 'temperature_C', 'student_density_index', 'foot_traffic_index', 'transactions_count', 'avg_order_value_NGN']:\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29266f76",
   "metadata": {},
   "source": [
    "### Looking for Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0764590",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df[num_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4463b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the correlation matrix using a heatmap\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Numeric Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e81d5",
   "metadata": {},
   "source": [
    "Understand the `correlation martix` before continuing with Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa214f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f009d66f",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Handle Missing Values\n",
    "- Define Variables\n",
    "- Feature Engineering & Featur Scaling where necessary\n",
    "- Encoding Categorical data\n",
    "\n",
    "\n",
    "`Note:` For Feature engineering on this project;\n",
    "\n",
    " Addressing Special Non-Public HolidaysYou should create a new binary feature specifically to capture the effect of fixed, non-official holidays that dramatically influence consumer spending and dining habits.\n",
    " 1. Create a New Feature: Festive_Day_FlagInstead of trying to fit Valentine's Day into the Is_Holiday column (which should be reserved only for nationally recognized public holidays), you should create a separate binary flag:\n",
    " \n",
    "- New Column Name:  Festive_Day_FlagBinary\n",
    "- DataType: (0 or 1)\n",
    "- Description : 1 if the date is a major, fixed festive day known to influence dining, 0 otherwise\n",
    "- Dates to Flag (Examples): February 14th (Valentine's), Mother's Day, Father's Day, New Year's Eve (Dec 31st).\n",
    "\n",
    "\n",
    "`Note:` for Encoding Categorical Data;\n",
    "1. One-Hot Encoding (Dummy Variables)\n",
    "Best for tree-based models (Random Forest, XGBoost) and linear models.\n",
    "`df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)`\n",
    "\n",
    "- drop_first=True avoids multicollinearity by removing one category per feature.\n",
    "- This turns each category into a binary column (0 or 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering #Lag Features\n",
    "# Sales lags\n",
    "df['sales_lag_1'] = df['daily_sales_NGN'].shift(1)\n",
    "df['sales_lag_7'] = df['daily_sales_NGN'].shift(7)\n",
    "df['sales_lag_30'] = df['daily_sales_NGN'].shift(30)\n",
    "\n",
    "# Foot traffic lags\n",
    "df['traffic_lag_1'] = df['foot_traffic_index'].shift(1)\n",
    "df['traffic_lag_7'] = df['foot_traffic_index'].shift(7)\n",
    "\n",
    "# Transactions lags\n",
    "df['transactions_lag_1'] = df['transactions_count'].shift(1)\n",
    "df['transactions_lag_7'] = df['transactions_count'].shift(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling averages; helps the model understand recent trends and smooth out daily noise.\n",
    "\n",
    "# Rolling averages for sales\n",
    "df['sales_7d_avg'] = df['daily_sales_NGN'].rolling(window=7).mean()\n",
    "df['sales_30d_avg'] = df['daily_sales_NGN'].rolling(window=30).mean()\n",
    "\n",
    "# Rolling averages for foot traffic and transactions\n",
    "df['traffic_7d_avg'] = df['foot_traffic_index'].rolling(window=7).mean()\n",
    "df['transactions_7d_avg'] = df['transactions_count'].rolling(window=7).mean()\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7842b9f1",
   "metadata": {},
   "source": [
    "Find answeres to this later;  If I drop the rows of the columns with NaN values, how will the model learn from the detials of their other colums with useful detials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6eacfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding non official public holidays or festive days that migh affect daily sales\n",
    "\n",
    "festive_days = [\n",
    "    '2021-02-14', '2021-03-14', '2021-06-20', '2021-12-24', '2021-12-31',\n",
    "    '2022-02-14', '2022-03-27', '2022-06-19', '2022-12-24', '2022-12-31',\n",
    "    '2023-02-14', '2023-03-19', '2023-06-18', '2023-12-24', '2023-12-31',\n",
    "    '2024-02-14', '2024-03-10', '2024-06-16', '2024-12-24', '2024-12-31',\n",
    "    '2025-02-14', '2025-03-30', '2025-06-15', '2025-12-24', '2025-12-31'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the names of the non official public holidays\n",
    "\n",
    "festive_names = {\n",
    "    '2021-02-14': \"Valentine's Day\",\n",
    "    '2021-03-14': \"Mother's Day\",\n",
    "    '2021-06-20': \"Father's Day\",\n",
    "    '2021-12-24': \"Christmas Eve\",\n",
    "    '2021-12-31': \"New Year's Eve\",\n",
    "    '2022-02-14': \"Valentine's Day\",\n",
    "    '2022-03-27': \"Mother's Day\",\n",
    "    '2022-06-19': \"Father's Day\",\n",
    "    '2022-12-24': \"Christmas Eve\",\n",
    "    '2022-12-31': \"New Year's Eve\",\n",
    "    '2023-02-14': \"Valentine's Day\",\n",
    "    '2023-03-19': \"Mother's Day\",\n",
    "    '2023-06-18': \"Father's Day\",\n",
    "    '2023-12-24': \"Christmas Eve\",\n",
    "    '2023-12-31': \"New Year's Eve\",\n",
    "    '2024-02-14': \"Valentine's Day\",\n",
    "    '2024-03-10': \"Mother's Day\",\n",
    "    '2024-06-16': \"Father's Day\",\n",
    "    '2024-12-24': \"Christmas Eve\",\n",
    "    '2024-12-31': \"New Year's Eve\",\n",
    "    '2025-02-14': \"Valentine's Day\",\n",
    "    '2025-03-30': \"Mother's Day\",\n",
    "    '2025-06-15': \"Father's Day\",\n",
    "    '2025-12-24': \"Christmas Eve\",\n",
    "    '2025-12-31': \"New Year's Eve\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b74d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Date Column to String Format for mapping\n",
    "df['date_str'] = df['date'].dt.strftime('%Y-%m-%d') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the colums to include festive days and their names\n",
    "df.loc[df['date_str'].isin(festive_days), 'is_holiday'] = True\n",
    "\n",
    "\n",
    "# Append festive names to public holiday name\n",
    "df['public_holiday_name'] = df.apply(\n",
    "    lambda row: festive_names[row['date_str']] if row['date_str'] in festive_names\n",
    "    else row['public_holiday_name'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['date_str'], inplace=True) #drop the date column in str format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4fe15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52beb334",
   "metadata": {},
   "source": [
    "- Cyclical Time Encoding ‚Äî turn day_of_week and month into sine/cosine features\n",
    "- Train-Test Split ‚Äî prepare your data for modeling\n",
    "- Feature Selection ‚Äî identify the most predictive features\n",
    "- Modeling ‚Äî build and evaluate your forecasting model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58eced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values after Feature Engineering\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling NaNs in 'public_holiday_name'\n",
    "df['public_holiday_name'] = df['public_holiday_name'].fillna('None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.dropna().copy()  # drop rows with any remaining NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdcf727",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0319934",
   "metadata": {},
   "source": [
    "### Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab06199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cyclical encoding of date features\n",
    "df['day_of_week'] = df['date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['month'] = df['date'].dt.month            # January=1, December=12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadf6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sine and cosine transformations\n",
    "import numpy as np\n",
    "\n",
    "# Day of week (7-day cycle)\n",
    "df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "# Month (12-month cycle)\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6163f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['university_calendar_status'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd364b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical columns \n",
    "df = pd.get_dummies(df, columns=[df.columns[6], df.columns[8]], drop_first=True)\n",
    "\n",
    "# Encoding boolean columns as integers\n",
    "bool_cols = ['is_weekend', 'is_holiday', 'is_school_in_session', 'promotion']\n",
    "for col in bool_cols:\n",
    "    df[col] = df[col].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a1cb8",
   "metadata": {},
   "source": [
    "### Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de82431",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['traffic_promo'] = df['foot_traffic_index'] * df['promotion']\n",
    "df['holiday_promo'] = df['is_holiday'] * df['promotion']\n",
    "df['weekend_promo'] = df['is_weekend'] * df['promotion']\n",
    "df['school_promo'] = df['is_school_in_session'] * df['promotion']\n",
    "df['holiday_traffic'] = df['is_holiday'] * df['foot_traffic_index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29512b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4affd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating Features and Target Variable\n",
    "\n",
    "X = df.drop(columns=['daily_sales_NGN', 'date', 'public_holiday_name']) #Features\n",
    "y = df['daily_sales_NGN'] #Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1314083c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50def3e9",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d248e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c18ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62548d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling for Linear Regression Model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a38f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bae4c4ce",
   "metadata": {},
   "source": [
    "## Train or Fit the Model into the Training Dataset;\n",
    "- Linear Regression Model\n",
    "- Random Forest \n",
    "- XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2198df0",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Linear Regression Model on the Scaled Data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c81c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test Set Results\n",
    "y_pred = regressor.predict(X_test_scaled)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be308e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Linear Regression Predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.values, label='Actual', linewidth=2)\n",
    "plt.plot(y_pred, label='Predicted', linestyle='--')\n",
    "plt.title('Linear Regression: Actual vs Predicted Sales')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sales (NGN)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4609ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating model performance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R¬≤ Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cee3a6",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b248ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Random Forest Regression Model into the Dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=300, random_state=0)\n",
    "rf_regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ac948",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = rf_regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea302f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56224a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Random Forest Predictions on Test Set\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.values, label='Actual', linewidth=2)\n",
    "plt.plot(rf_y_pred, label='Predicted(RF)', linestyle='--')\n",
    "plt.title('Random Forest Regression: Actual vs Predicted Sales')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sales (NGN)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    " # Visualizing the Random Forest Predictions on Train Set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_train.values, label='Actual', linewidth=2)\n",
    "plt.plot(rf_regressor.predict(X_train), label='Predicted (RF)', linestyle='--')\n",
    "plt.title('Random Forest: Actual vs Predicted Sales')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sales (NGN)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluting model performance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae_rf = mean_absolute_error(y_test, rf_y_pred)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, rf_y_pred))\n",
    "r2_rf = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "print(f\"Random Forest MAE: {mae_rf:.2f}\")\n",
    "print(f\"Random Forest RMSE: {rmse_rf:.2f}\")\n",
    "print(f\"Random Forest R¬≤: {r2_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance from Random Forest Model\n",
    "import pandas as pd\n",
    "\n",
    "feature_importance = rf_regressor.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ddf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Feature Importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Refinement; Filter out the features with low importance and keep the ones with high importance(top 10)\n",
    "\n",
    "top_features = importance_df['Feature'].head(10).tolist()\n",
    "X_train_reduced = X_train[top_features]\n",
    "X_test_reduced = X_test[top_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0db83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try retraining with only the top 10 features\n",
    "\n",
    "rf_regressor_reduced = RandomForestRegressor(n_estimators=300, random_state=0)\n",
    "rf_regressor_reduced.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6906d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred_reduced = rf_regressor_reduced.predict(X_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluting the Refined model performance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae_rf = mean_absolute_error(y_test, rf_y_pred_reduced)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, rf_y_pred_reduced))\n",
    "r2_rf = r2_score(y_test, rf_y_pred_reduced)\n",
    "\n",
    "print(f\"Random Forest MAE: {mae_rf:.2f}\")\n",
    "print(f\"Random Forest RMSE: {rmse_rf:.2f}\")\n",
    "print(f\"Random Forest R¬≤: {r2_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8ab6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffa097fe",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the XGBoost Regression Model into the Dataset using the redudced feature set\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_regressor = XGBRegressor(n_estimators=300, learning_rate=0.1, max_depth=6, random_state=0)\n",
    "xgb_regressor.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_y_pred = xgb_regressor.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73429ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd784892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the XGBoost Predictions on Test Set\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.values, label='Actual', linewidth=2)\n",
    "plt.plot(xgb_y_pred, label='Predicted(RF)', linestyle='--')\n",
    "plt.title('XGBoost: Actual vs Predicted Sales')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sales (NGN)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    " # Visualizing the XGBoost Predictions on Train Set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_train.values, label='Actual', linewidth=2)\n",
    "plt.plot(xgb_regressor.predict(X_train_reduced), label='Predicted (RF)', linestyle='--')\n",
    "plt.title('XGBoost: Actual vs Predicted Sales')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sales (NGN)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ec2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluting XGBoost model performance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae_xgb = mean_absolute_error(y_test, xgb_y_pred)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, xgb_y_pred))\n",
    "r2_xgb = r2_score(y_test, xgb_y_pred)\n",
    "\n",
    "print(f\"XGBoost MAE: {mae_xgb:.2f}\")\n",
    "print(f\"XGBoost RMSE: {rmse_xgb:.2f}\")\n",
    "print(f\"XGBoost R¬≤: {r2_xgb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine Tiuning and Hyperparameter Optimization can be done using GridSearchCV or RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf566ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "y_pred_best = best_model.predict(X_test_reduced)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
    "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Best XGBoost MAE: {mae_best:.2f}\")\n",
    "print(f\"Best XGBoost RMSE: {rmse_best:.2f}\")\n",
    "print(f\"Best XGBoost R¬≤: {r2_best:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654cb49b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32a32421",
   "metadata": {},
   "source": [
    "## Finalize Model Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876102a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class CustomPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, top_features):\n",
    "        self.top_features = top_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "\n",
    "        # --- Feature Engineering ---\n",
    "        df['sales_lag_1'] = df['sales'].shift(1)\n",
    "        df['sales_lag_7'] = df['sales'].shift(7)\n",
    "        df['sales_lag_30'] = df['sales'].shift(30)\n",
    "        df['traffic_lag_1'] = df['traffic'].shift(1)\n",
    "        df['traffic_lag_7'] = df['traffic'].shift(7)\n",
    "        df['transactions_lag_1'] = df['transactions'].shift(1)\n",
    "        df['transactions_lag_7'] = df['transactions'].shift(7)\n",
    "\n",
    "        df['sales_7d_avg'] = df['sales'].rolling(7).mean()\n",
    "        df['sales_30d_avg'] = df['sales'].rolling(30).mean()\n",
    "        df['traffic_7d_avg'] = df['traffic'].rolling(7).mean()\n",
    "        df['transactions_7d_avg'] = df['transactions'].rolling(7).mean()\n",
    "\n",
    "        # --- Cyclical Time Encoding ---\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['day_of_week'] = df['date'].dt.dayofweek\n",
    "        df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "        df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "        # --- One-Hot Encoding ---\n",
    "        df = pd.get_dummies(df, columns=['store_type', 'region'], drop_first=True)\n",
    "\n",
    "        # --- Drop rows with NaNs from lag/rolling ---\n",
    "        df = df.dropna()\n",
    "\n",
    "        # --- Select Top Features ---\n",
    "        return df[self.top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "\n",
    "# Replace with your actual top 10 feature names\n",
    "top_10_features = ['sales_lag_1', 'sales_lag_7', 'traffic_lag_7', 'sales_7d_avg', 'sales_30d_avg', 'transactions_lag_7', 'traffic_7d_avg'. 'transactions_7d_avg', 'day_sin', 'store_type_TypeB']  # example\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', CustomPreprocessor(top_features=top_10_features)),\n",
    "    ('model', best_model)  # your tuned XGBoost model\n",
    "])\n",
    "\n",
    "# Fit on raw training data\n",
    "pipeline.fit(raw_X_train, y_train)\n",
    "\n",
    "# Save the full pipeline\n",
    "joblib.dump(pipeline, 'xgboost_full_pipeline_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77107dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "\n",
    "# Build pipeline with only the model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('model', best_model)\n",
    "])\n",
    "\n",
    "# Train the pipeline on your reduced, preprocessed data\n",
    "pipeline.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Save the pipeline\n",
    "joblib.dump(pipeline, 'xgboost_final_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I still want to make some changeseg add all the pre preocessing steps to the model pipeline before deploying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8fb25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77caed49",
   "metadata": {},
   "source": [
    "## Launch the Model on Streamlit app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c2adb",
   "metadata": {},
   "source": [
    " Let's Launch the model..\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba104b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c52eca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
